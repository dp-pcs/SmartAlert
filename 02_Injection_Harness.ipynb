{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß™ SmartAlert AI - Adaptive Training Injection Harness\n",
    "\n",
    "This notebook implements an **adaptive learning system** that simulates real-world deployment scenarios where:\n",
    "\n",
    "- **New log data arrives in batches** (simulating daily/hourly log ingestion)\n",
    "- **Models are retrained incrementally** as new data becomes available  \n",
    "- **Performance is tracked over time** to detect model drift\n",
    "- **Multiple model types** are compared for adaptability\n",
    "\n",
    "## üéØ Key Features\n",
    "\n",
    "- **Incremental Learning**: Models adapt to new data patterns over time\n",
    "- **Drift Detection**: Automatically identifies when model performance degrades\n",
    "- **Model Comparison**: Test RandomForest, XGBoost, and LightGBM adaptability\n",
    "- **Rich Feature Engineering**: Uses our comprehensive preprocessing pipeline\n",
    "- **Performance Visualization**: Track metrics across training rounds\n",
    "- **Production Ready**: Save model artifacts for deployment\n",
    "\n",
    "## üìä Use Cases\n",
    "\n",
    "1. **Online Learning Simulation**: How do models perform as new incident patterns emerge?\n",
    "2. **Model Selection**: Which algorithm adapts best to changing log patterns?\n",
    "3. **Drift Monitoring**: When should we retrain models in production?\n",
    "4. **Performance Benchmarking**: Compare adaptive vs static training approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from injection_harness import run_training_injection_harness, AdaptiveModelTracker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"üß™ SmartAlert AI - Adaptive Training System\")\n",
    "print(\"=\" * 50)\n",
    "print(\"üì¶ All libraries imported successfully!\")\n",
    "print(f\"‚è∞ Session started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Dataset Analysis\n",
    "# First, let's examine our V2 dataset\n",
    "df = pd.read_csv(\"data/splunk_logs_v2.csv\")\n",
    "\n",
    "print(\"üìà Dataset Overview:\")\n",
    "print(f\"   Total samples: {len(df):,}\")\n",
    "print(f\"   Columns: {list(df.columns)}\")\n",
    "print(f\"   Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"   Critical incidents: {df['critical'].sum():,} ({df['critical'].mean():.1%})\")\n",
    "\n",
    "print(\"\\nüéØ Target Distribution:\")\n",
    "print(df['critical'].value_counts())\n",
    "\n",
    "print(\"\\nüìä Feature Overview:\")\n",
    "print(f\"   Severity levels: {df['severity'].nunique()} ({list(df['severity'].unique())})\")\n",
    "print(f\"   Components: {df['component'].nunique()} ({list(df['component'].unique())})\")\n",
    "print(f\"   Message length range: {df['message_length'].min()}-{df['message_length'].max()}\")\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Run Adaptive Training - Single Model\n",
    "print(\"üîÑ Running adaptive training with XGBoost...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Run adaptive training with XGBoost\n",
    "results_xgb, tracker_xgb, final_model_xgb = run_training_injection_harness(\n",
    "    data_path=\"data/splunk_logs_v2.csv\",\n",
    "    model_name=\"xgb\",\n",
    "    batch_size=10000,\n",
    "    num_batches=5,\n",
    "    target_column=\"critical\",\n",
    "    timestamp_column=\"timestamp\",\n",
    "    output_dir=\"models/adaptive\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nüìä XGBoost Results Summary:\")\n",
    "print(results_xgb[['round', 'precision', 'recall', 'f1', 'auc', 'drift_detected']].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà Visualize XGBoost Performance Trends\n",
    "print(\"üìà Generating performance visualizations...\")\n",
    "\n",
    "# Use the tracker's built-in plotting function\n",
    "tracker_xgb.plot_performance()\n",
    "\n",
    "# Additional custom plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Performance metrics trend\n",
    "axes[0, 0].plot(results_xgb['round'], results_xgb['precision'], 'o-', label='Precision', linewidth=2)\n",
    "axes[0, 0].plot(results_xgb['round'], results_xgb['recall'], 's-', label='Recall', linewidth=2)\n",
    "axes[0, 0].plot(results_xgb['round'], results_xgb['f1'], '^-', label='F1-Score', linewidth=2)\n",
    "axes[0, 0].set_title('üìä Performance Metrics Over Time')\n",
    "axes[0, 0].set_xlabel('Training Round')\n",
    "axes[0, 0].set_ylabel('Score')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Drift detection\n",
    "drift_rounds = results_xgb[results_xgb['drift_detected']]['round']\n",
    "axes[0, 1].plot(results_xgb['round'], results_xgb['f1'], 'b-o', linewidth=2, label='F1-Score')\n",
    "for round_num in drift_rounds:\n",
    "    axes[0, 1].axvline(x=round_num, color='red', linestyle='--', alpha=0.7, label='Drift Detected' if round_num == drift_rounds.iloc[0] else \"\")\n",
    "axes[0, 1].set_title('üö® Model Drift Detection')\n",
    "axes[0, 1].set_xlabel('Training Round')\n",
    "axes[0, 1].set_ylabel('F1-Score')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Sample growth\n",
    "axes[1, 0].bar(results_xgb['round'], results_xgb['cumulative_samples'], alpha=0.7, color='green')\n",
    "axes[1, 0].set_title('üìà Cumulative Training Data')\n",
    "axes[1, 0].set_xlabel('Training Round')\n",
    "axes[1, 0].set_ylabel('Total Samples')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Critical incident rate per round\n",
    "axes[1, 1].plot(results_xgb['round'], results_xgb['critical_rate'], 'ro-', linewidth=2)\n",
    "axes[1, 1].set_title('üéØ Critical Incident Rate')\n",
    "axes[1, 1].set_xlabel('Training Round')\n",
    "axes[1, 1].set_ylabel('Critical Rate')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ XGBoost adaptive training completed!\")\n",
    "print(f\"   Best F1-Score: {results_xgb['f1'].max():.4f}\")\n",
    "print(f\"   Drift detected in: {len(drift_rounds)} rounds\")\n",
    "print(f\"   Final model available: {final_model_xgb is not None}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
